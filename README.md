# E-Test-package

This artifact contains the environment, code, and data required to fully replicate the results of our ICSE 2026 paper.

### ðŸ“„ Paper Details

**[E-Test: E'er-Improving Test Suites](https://conf.researchr.org/details/icse-2026/icse-2026-research-track/84/E-Test-E-er-Improving-Test-Suites)**
*Accepted at the 48th International Conference on Software Engineering (ICSE 2026)*

**Authors:** Ketai Qiu, Luca Di Grazia, Leonardo Mariani, and Mauro PezzÃ¨.

### ðŸ”— Resources

* **Paper PDF:** [Read here](https://arxiv.org/pdf/2510.19860)
* **Source Code:** [GitHub Repository](https://github.com/ketaiq/E-Test-package)

## Repository Structure

* **AutonomicTester:** A Python application designed to implement advanced techniques for E-TEST.
* **DataAnalysis:** A set of Jupyter notebooks to analyze results and compute evaluation metrics.
* **Archives:** A set of tar archives of datasets of prompts and responses from LLMs.

## Getting Started

### Environment Setup

1. Create a HuggingFace user access token on [https://huggingface.co/docs/hub/security-tokens](https://huggingface.co/docs/hub/security-tokens).

2. Install [Docker](https://docs.docker.com/engine/install/).

3. Create a `.env` file in the project root with the following content:

```env
HUGGING_FACE_API_KEY=your_huggingface_token_here
OLLAMA_MODEL=llama3.2:1b
```

4. Build and run the Docker container using Docker Compose:

```sh
docker-compose up --build
```

5. Open another terminal and enter the container:

```sh
docker exec -it e-test /bin/bash
```

### Data Analysis

To reproduce evaluation results shown in the paper, please run notebooks in the `DataAnalysis` folder. You can open [http://localhost:20268](http://localhost:20268) to run and edit notebooks directly.

* `Dataset Stats.ipynb` and `GH Dataset Stats.ipynb` compute statistics about the dataset, corresponding to **Section 2.2 Dataset paragraph** and **Table 1** in the paper.
* `RQ1 Impact of LLMs.ipynb` computes evaluation metrics (precision, recall, and F1-score) for each scenario and the average F1-scores, corresponding to **Section 3.1**, **Table 3**, **Figure 3**, and **Figure 4**.
* `RQ2 Comparative Evaluation.ipynb` computes metrics of two state-of-the-art approaches (*FAST++* and *Field-ready testing*), corresponding to **Section 3.2** and **Table 3**.
* `RQ3 Impact of Queries.ipynb` computes metrics for different query combinations, corresponding to **Section 3.3** and **Figure 5**.
* `RQ4 Efficiency.ipynb` measures E-Test efficiency in terms of response time and token consumption, corresponding to **Section 3.4** and **Figure 6**.
* `RQ5 Test Case Generation.ipynb` analyzes JUnit test cases generated by E-Test, corresponding to **Section 3.5** and **Figure 7**.

### E-Test Program

In the Docker interactive shell, run the following command to launch an experiment:

```sh
python AutonomicTester/main.py prompt -v 4 -d Defects4J -m LLama3_2_1B -s BUGGY
```

to enable test case generation add `--generate_test_case` flag



For other settings mentioned in the paper, check the help message via:

```sh
python AutonomicTester/main
```
