# E-Test-package

This replication package can be used to fully replicate the results of our paper [*E-Test: E'er-Improving Test Suites*](https://star.inf.usi.ch/media/papers/2026-icse-etest-ketai.pdf) by Ketai Qiu, Luca Di Grazia, Leonardo Mariani and Mauro Pezz√®.

## Repository Structure
- **AutonomicTester:** A Python application designed to implement advanced techniques for E-TEST.
- **DataAnalysis:** A set of Jupyter notebooks to analyze results and compute evaluation metrics.
- **Archives:** A set of tar archives of datasets of prompts and responses from LLMs.

## Getting Started

### Environment Setup
Create a HuggingFace user access token on https://huggingface.co/docs/hub/security-tokens

Run following commands from project root directory

```sh
export HUGGING_FACE_API_KEY="YOUR API KEY"

docker build -t e-test-env .

docker run -it --rm \
  -p 20268:8888 \
  -v $(pwd):/app \
  -v ollama_storage:/root/.ollama \
  -e HUGGING_FACE_API_KEY=$HUGGING_FACE_API_KEY \
  -e OLLAMA_MODEL="llama3.2:1b" \
  e-test-env
```

### Data Analysis
To reproduce evaluation results shown in the paper, please run notebooks in `DataAnalysis` folder.
You can open http://localhost:20268 to run and edit notebooks directly.

- `Dataset Stats.ipynb` and `GH Dataset Stats.ipynb` compute statistics about the dataset, which corresponds to **Section 2.2 Dataset paragraph**, and **Table 1** in the paper.
- `RQ1 Impact of LLMs.ipynb` computes evaluation metrics (precision, recall, and F1-score) for each scenario and the average F1-scores, which corresponds to **Section 3.1**, **Table 3**, **Figure 3** and **Figure 4** in the paper.
- `RQ2 Comparative Evaluation.ipynb` computes evaluation metrics of two state-of-the-art approaches (i.e., *FAST++* and *Field-ready testing*), which corresponds to **Section 3.2** and **Table 3** in the paper.
- `RQ3 Impact of Queries.ipynb` computes evaluation metrics for different combinations of queries, which corresponds to **Section 3.3** and **Figure 5** in the paper.
- `RQ4 Efficiency.ipynb` measures efficiency of E-Test in terms of response time and token consumption, which corresponds to **Section 3.4** and **Figure 6** in the paper.
- `RQ5 Test Case Generation.ipynb` analyzes JUnit test cases generated by E-Test, which corresponds to **Section 3.5** and **Figure 7** in the paper.

### E-Test Program

In the Docker interactive shell, run the following command to launch an experiment
```sh
# Test Llama3 1B with prompts generated from error-prone scenarios in Defects4J
python AutonomicTester/main.py prompt -v 4 -d Defects4J -m LLama3_2_1B -s BUGGY
```

For other settings mentioned in the paper, please check the help message via `python AutonomicTester/main.py -h`.

Run `exit` to stop the Docker container.